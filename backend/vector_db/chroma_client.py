import chromadb
import os
import torch
from sentence_transformers import SentenceTransformer
from chromadb.utils.embedding_functions import EmbeddingFunction

# Force GPU usage for embeddings
os.environ["CUDA_VISIBLE_DEVICES"] = "0"

### GPUEmbeddingFunction - Generated by Claude Haiku 4.5 on 2026-02-05
### Prompt: Create a custom embedding function that explicitly uses GPU for sentence-transformers
### Model: all-MiniLM-L6-v2 | Purpose: Enable GPU acceleration for vector embeddings in ChromaDB
###

class GPUEmbeddingFunction(EmbeddingFunction):
    """Custom embedding function that attempts GPU, falls back to CPU if needed"""
    def __init__(self, model_name="all-MiniLM-L6-v2"):
        # Try GPU first
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"Loading model on device: {self.device}")
        self.model = SentenceTransformer(model_name, device=self.device)
        self.gpu_available = torch.cuda.is_available()
        print(f"Model loaded successfully on {self.device}")

    def __call__(self, texts):
        """Embed texts, fall back to CPU if CUDA kernel not available"""
        if isinstance(texts, str):
            texts = [texts]

        try:
            embeddings = self.model.encode(texts, convert_to_numpy=True)
            return embeddings.tolist()
        except RuntimeError as e:
            if "CUDA" in str(e) and self.gpu_available:
                print(f"\n⚠️  CUDA kernel not available for RTX 5080, falling back to CPU")
                self.device = "cpu"
                self.model = self.model.to("cpu")
                self.gpu_available = False
                embeddings = self.model.encode(texts, convert_to_numpy=True)
                return embeddings.tolist()
            else:
                raise

### End AI GENERATED CODE ---- GPUEmbeddingFunction ###

def get_client(db_path="./chroma_db"):
    # Store the GPU embedding function globally so it can be reused
    if not hasattr(get_client, 'embedding_fn'):
        get_client.embedding_fn = GPUEmbeddingFunction()
    return chromadb.PersistentClient(path=db_path)

def get_embedding_function():
    """Get the GPU embedding function for use with collections"""
    if not hasattr(get_client, 'embedding_fn'):
        get_client.embedding_fn = GPUEmbeddingFunction()
    return get_client.embedding_fn
